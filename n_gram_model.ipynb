{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation of the Trigram Language Model Code\n",
        "\n",
        "#### 1. Overview\n",
        "\n",
        "The code implements a **trigram language model** for predicting the next word given a context of two words. In an n-gram model, we assume that the probability of a word depends only on the preceding $n-1$ words. For a trigram model (where $n = 3$), the probability of a word $w_i$ given the two preceding words $w_{i-2}$ and $w_{i-1}$ is estimated as:\n",
        "\n",
        "$$\n",
        "P(w_i \\mid w_{i-2}, w_{i-1}) = \\frac{\\text{Count}(w_{i-2}, w_{i-1}, w_i)}{\\text{Count}(w_{i-2}, w_{i-1})},\n",
        "$$\n",
        "\n",
        "where  \n",
        "- $\\text{Count}(w_{i-2}, w_{i-1}, w_i)$ is the frequency of the trigram (three-word sequence) in the corpus, and  \n",
        "- $\\text{Count}(w_{i-2}, w_{i-1})$ is the frequency of the two-word context.\n",
        "\n",
        "This model supports two main tasks:  \n",
        "1. **Next-Word Prediction:** Given a two-word context, the model predicts the most likely next word.  \n",
        "2. **Sentence Completion:** Starting with an initial phrase, the model iteratively predicts and appends words until a desired sentence length is reached or no prediction is available.\n",
        "\n",
        "---\n",
        "\n",
        "#### 2. Detailed Breakdown\n",
        "\n",
        "**Step 1: Preprocessing the Corpus**\n",
        "\n",
        "- **Corpus Definition:**  \n",
        "  A larger corpus with multiple sentences and paragraphs is defined. This narrative-style text contains diverse contexts, ensuring the model learns various word sequences.\n",
        "\n",
        "- **Tokenization:**  \n",
        "  The `tokenize` function performs the following:\n",
        "  - Converts the text to lowercase (to ensure consistency),\n",
        "  - Removes punctuation and non-alphabetical characters (to clean the text), and\n",
        "  - Splits the text into individual tokens (words).\n",
        "\n",
        "  This preprocessing step prepares the text for building the n-gram counts.\n",
        "\n",
        "**Step 2: Building Trigram Counts**\n",
        "\n",
        "- **Trigram Definition:**  \n",
        "  A trigram is a sequence of three consecutive words, written as $(w_{i-2}, w_{i-1}, w_i)$.  \n",
        "  The code iterates over the tokenized corpus and, for each window of three words, treats the first two words as the context and the third word as the target.\n",
        "\n",
        "- **Counting Occurrences:**  \n",
        "  A Python dictionary (specifically, a `defaultdict` of `Counter` objects) is used to record how many times each two-word context is followed by a specific next word. These counts form the basis for estimating conditional probabilities.\n",
        "\n",
        "- **Vocabulary Extraction:**  \n",
        "  The vocabulary is the set of all unique words in the corpus. Sorting the vocabulary alphabetically simplifies display and analysis.\n",
        "\n",
        "**Step 3: Defining Prediction Functions**\n",
        "\n",
        "- **Next-Word Prediction (`predict_next_word`):**  \n",
        "  This function takes a context (a tuple of two words) and returns the most frequent word that follows that context. In effect, it chooses the word $w$ that maximizes $\\text{Count}(c, w)$, where $c$ is the context.\n",
        "\n",
        "- **Full Probability Distribution (`get_full_next_word_probabilities`):**  \n",
        "  For a given context $c$, this function computes the probability of each word $w$ in the vocabulary being the next word, using:\n",
        "\n",
        "  $$\n",
        "  P(w \\mid c) = \\begin{cases}\n",
        "  \\displaystyle \\frac{\\text{Count}(c, w)}{\\sum_{w'} \\text{Count}(c, w')}, & \\text{if } c \\text{ is found}, \\\\\n",
        "  0, & \\text{otherwise}.\n",
        "  \\end{cases}\n",
        "  $$\n",
        "\n",
        "  This provides a full distribution, allowing us to see the likelihood of every possible next word.\n",
        "\n",
        "**Step 4: Demonstrating the Probability Distributions**\n",
        "\n",
        "- The code tests multiple sample contexts (for example, $('the', 'knight')$, $('once', 'upon')$, etc.) and prints the complete probability distribution for each.\n",
        "- The distributions are sorted in descending order of probability, clearly showing which words are most likely to follow each context.\n",
        "\n",
        "**Step 5: Sentence Completion**\n",
        "\n",
        "- **Functionality:**  \n",
        "  The `complete_sentence` function takes a starting sentence and repeatedly predicts the next word using the trigram model until either a maximum word count is reached or no further prediction is available.\n",
        "\n",
        "- **Process:**  \n",
        "  1. The input sentence is tokenized.\n",
        "  2. The last two tokens are used as the current context.\n",
        "  3. The model predicts the next word, which is then appended to the sentence.\n",
        "  4. This process repeats until the sentence reaches the desired length.\n",
        "\n",
        "This function demonstrates how the trigram model can generate extended text by iteratively applying the learned n-gram statistics.\n",
        "\n",
        "---\n",
        "\n",
        "#### 3. So in short:\n",
        "\n",
        "- **Preprocessing:**  \n",
        "  The corpus is standardized by converting to lowercase, cleaning punctuation, and tokenizing into words, ensuring consistent input for the model.\n",
        "\n",
        "- **Trigram Model:**  \n",
        "  The model counts occurrences of trigrams and estimates the probability of a word $w_i$ following a two-word context $(w_{i-2}, w_{i-1})$ using:\n",
        "\n",
        "  $$\n",
        "  P(w_i \\mid w_{i-2}, w_{i-1}) = \\frac{\\text{Count}(w_{i-2}, w_{i-1}, w_i)}{\\text{Count}(w_{i-2}, w_{i-1})}.\n",
        "  $$\n",
        "\n",
        "- **Prediction Functions:**  \n",
        "  Two functions are defined: one to predict the most likely next word and another to compute the full probability distribution over the vocabulary for a given context.\n",
        "\n",
        "- **Sentence Generation:**  \n",
        "  The sentence completion function leverages the trigram model to generate longer text by iteratively predicting and appending words based on the current context.\n"
      ],
      "metadata": {
        "id": "ip1s3AUrpvKy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLs5flydoBNG",
        "outputId": "c3357651-1e73-4c35-ce9a-6fb561150a29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Tokens from the corpus:\n",
            "['once', 'upon', 'a', 'time', 'in', 'a', 'land', 'far', 'away', 'there', 'lived', 'a', 'brave', 'knight', 'the', 'knight', 'was', 'known', 'for', 'his', 'valor', 'and', 'courage', 'and', 'many', 'stories', 'of', 'his', 'adventures', 'were', 'told', 'throughout', 'the', 'kingdom', 'the', 'knight', 'journeyed', 'through', 'mysterious', 'forests', 'fought', 'fierce', 'dragons', 'and', 'helped', 'those', 'in', 'need', 'his', 'story', 'was', 'an', 'inspiration', 'to', 'all', 'who', 'heard', 'it', 'in', 'a', 'small', 'village', 'the', 'people', 'would', 'often', 'speak', 'of', 'the', 'knights', 'exploits', 'the', 'villagers', 'believed', 'that', 'one', 'day', 'the', 'knight', 'would', 'return', 'to', 'save', 'them', 'from', 'impending', 'doom', 'meanwhile', 'the', 'kingdom', 'thrived', 'with', 'tales', 'of', 'heroism', 'and', 'hope', 'the', 'knights', 'legacy', 'continued', 'to', 'grow', 'as', 'his', 'adventures', 'were', 'recounted', 'by', 'bards', 'and', 'storytellers', 'as', 'time', 'passed', 'legends', 'and', 'myths', 'were', 'born', 'from', 'his', 'deeds', 'every', 'town', 'had', 'a', 'story', 'and', 'every', 'child', 'dreamed', 'of', 'a', 'hero', 'like', 'him']\n",
            "\n",
            "2. Vocabulary (sorted alphabetically):\n",
            "1. a\n",
            "2. adventures\n",
            "3. all\n",
            "4. an\n",
            "5. and\n",
            "6. as\n",
            "7. away\n",
            "8. bards\n",
            "9. believed\n",
            "10. born\n",
            "11. brave\n",
            "12. by\n",
            "13. child\n",
            "14. continued\n",
            "15. courage\n",
            "16. day\n",
            "17. deeds\n",
            "18. doom\n",
            "19. dragons\n",
            "20. dreamed\n",
            "21. every\n",
            "22. exploits\n",
            "23. far\n",
            "24. fierce\n",
            "25. for\n",
            "26. forests\n",
            "27. fought\n",
            "28. from\n",
            "29. grow\n",
            "30. had\n",
            "31. heard\n",
            "32. helped\n",
            "33. hero\n",
            "34. heroism\n",
            "35. him\n",
            "36. his\n",
            "37. hope\n",
            "38. impending\n",
            "39. in\n",
            "40. inspiration\n",
            "41. it\n",
            "42. journeyed\n",
            "43. kingdom\n",
            "44. knight\n",
            "45. knights\n",
            "46. known\n",
            "47. land\n",
            "48. legacy\n",
            "49. legends\n",
            "50. like\n",
            "51. lived\n",
            "52. many\n",
            "53. meanwhile\n",
            "54. mysterious\n",
            "55. myths\n",
            "56. need\n",
            "57. of\n",
            "58. often\n",
            "59. once\n",
            "60. one\n",
            "61. passed\n",
            "62. people\n",
            "63. recounted\n",
            "64. return\n",
            "65. save\n",
            "66. small\n",
            "67. speak\n",
            "68. stories\n",
            "69. story\n",
            "70. storytellers\n",
            "71. tales\n",
            "72. that\n",
            "73. the\n",
            "74. them\n",
            "75. there\n",
            "76. those\n",
            "77. thrived\n",
            "78. through\n",
            "79. throughout\n",
            "80. time\n",
            "81. to\n",
            "82. told\n",
            "83. town\n",
            "84. upon\n",
            "85. valor\n",
            "86. village\n",
            "87. villagers\n",
            "88. was\n",
            "89. were\n",
            "90. who\n",
            "91. with\n",
            "92. would\n",
            "\n",
            "3. Trigram Counts (contexts with their next words and counts):\n",
            "1. Context ('once', 'upon'): {'a': 1}\n",
            "2. Context ('upon', 'a'): {'time': 1}\n",
            "3. Context ('a', 'time'): {'in': 1}\n",
            "4. Context ('time', 'in'): {'a': 1}\n",
            "5. Context ('in', 'a'): {'land': 1, 'small': 1}\n",
            "6. Context ('a', 'land'): {'far': 1}\n",
            "7. Context ('land', 'far'): {'away': 1}\n",
            "8. Context ('far', 'away'): {'there': 1}\n",
            "9. Context ('away', 'there'): {'lived': 1}\n",
            "10. Context ('there', 'lived'): {'a': 1}\n",
            "11. Context ('lived', 'a'): {'brave': 1}\n",
            "12. Context ('a', 'brave'): {'knight': 1}\n",
            "13. Context ('brave', 'knight'): {'the': 1}\n",
            "14. Context ('knight', 'the'): {'knight': 1}\n",
            "15. Context ('the', 'knight'): {'was': 1, 'journeyed': 1, 'would': 1}\n",
            "16. Context ('knight', 'was'): {'known': 1}\n",
            "17. Context ('was', 'known'): {'for': 1}\n",
            "18. Context ('known', 'for'): {'his': 1}\n",
            "19. Context ('for', 'his'): {'valor': 1}\n",
            "20. Context ('his', 'valor'): {'and': 1}\n",
            "21. Context ('valor', 'and'): {'courage': 1}\n",
            "22. Context ('and', 'courage'): {'and': 1}\n",
            "23. Context ('courage', 'and'): {'many': 1}\n",
            "24. Context ('and', 'many'): {'stories': 1}\n",
            "25. Context ('many', 'stories'): {'of': 1}\n",
            "26. Context ('stories', 'of'): {'his': 1}\n",
            "27. Context ('of', 'his'): {'adventures': 1}\n",
            "28. Context ('his', 'adventures'): {'were': 2}\n",
            "29. Context ('adventures', 'were'): {'told': 1, 'recounted': 1}\n",
            "30. Context ('were', 'told'): {'throughout': 1}\n",
            "31. Context ('told', 'throughout'): {'the': 1}\n",
            "32. Context ('throughout', 'the'): {'kingdom': 1}\n",
            "33. Context ('the', 'kingdom'): {'the': 1, 'thrived': 1}\n",
            "34. Context ('kingdom', 'the'): {'knight': 1}\n",
            "35. Context ('knight', 'journeyed'): {'through': 1}\n",
            "36. Context ('journeyed', 'through'): {'mysterious': 1}\n",
            "37. Context ('through', 'mysterious'): {'forests': 1}\n",
            "38. Context ('mysterious', 'forests'): {'fought': 1}\n",
            "39. Context ('forests', 'fought'): {'fierce': 1}\n",
            "40. Context ('fought', 'fierce'): {'dragons': 1}\n",
            "41. Context ('fierce', 'dragons'): {'and': 1}\n",
            "42. Context ('dragons', 'and'): {'helped': 1}\n",
            "43. Context ('and', 'helped'): {'those': 1}\n",
            "44. Context ('helped', 'those'): {'in': 1}\n",
            "45. Context ('those', 'in'): {'need': 1}\n",
            "46. Context ('in', 'need'): {'his': 1}\n",
            "47. Context ('need', 'his'): {'story': 1}\n",
            "48. Context ('his', 'story'): {'was': 1}\n",
            "49. Context ('story', 'was'): {'an': 1}\n",
            "50. Context ('was', 'an'): {'inspiration': 1}\n",
            "51. Context ('an', 'inspiration'): {'to': 1}\n",
            "52. Context ('inspiration', 'to'): {'all': 1}\n",
            "53. Context ('to', 'all'): {'who': 1}\n",
            "54. Context ('all', 'who'): {'heard': 1}\n",
            "55. Context ('who', 'heard'): {'it': 1}\n",
            "56. Context ('heard', 'it'): {'in': 1}\n",
            "57. Context ('it', 'in'): {'a': 1}\n",
            "58. Context ('a', 'small'): {'village': 1}\n",
            "59. Context ('small', 'village'): {'the': 1}\n",
            "60. Context ('village', 'the'): {'people': 1}\n",
            "61. Context ('the', 'people'): {'would': 1}\n",
            "62. Context ('people', 'would'): {'often': 1}\n",
            "63. Context ('would', 'often'): {'speak': 1}\n",
            "64. Context ('often', 'speak'): {'of': 1}\n",
            "65. Context ('speak', 'of'): {'the': 1}\n",
            "66. Context ('of', 'the'): {'knights': 1}\n",
            "67. Context ('the', 'knights'): {'exploits': 1, 'legacy': 1}\n",
            "68. Context ('knights', 'exploits'): {'the': 1}\n",
            "69. Context ('exploits', 'the'): {'villagers': 1}\n",
            "70. Context ('the', 'villagers'): {'believed': 1}\n",
            "71. Context ('villagers', 'believed'): {'that': 1}\n",
            "72. Context ('believed', 'that'): {'one': 1}\n",
            "73. Context ('that', 'one'): {'day': 1}\n",
            "74. Context ('one', 'day'): {'the': 1}\n",
            "75. Context ('day', 'the'): {'knight': 1}\n",
            "76. Context ('knight', 'would'): {'return': 1}\n",
            "77. Context ('would', 'return'): {'to': 1}\n",
            "78. Context ('return', 'to'): {'save': 1}\n",
            "79. Context ('to', 'save'): {'them': 1}\n",
            "80. Context ('save', 'them'): {'from': 1}\n",
            "81. Context ('them', 'from'): {'impending': 1}\n",
            "82. Context ('from', 'impending'): {'doom': 1}\n",
            "83. Context ('impending', 'doom'): {'meanwhile': 1}\n",
            "84. Context ('doom', 'meanwhile'): {'the': 1}\n",
            "85. Context ('meanwhile', 'the'): {'kingdom': 1}\n",
            "86. Context ('kingdom', 'thrived'): {'with': 1}\n",
            "87. Context ('thrived', 'with'): {'tales': 1}\n",
            "88. Context ('with', 'tales'): {'of': 1}\n",
            "89. Context ('tales', 'of'): {'heroism': 1}\n",
            "90. Context ('of', 'heroism'): {'and': 1}\n",
            "91. Context ('heroism', 'and'): {'hope': 1}\n",
            "92. Context ('and', 'hope'): {'the': 1}\n",
            "93. Context ('hope', 'the'): {'knights': 1}\n",
            "94. Context ('knights', 'legacy'): {'continued': 1}\n",
            "95. Context ('legacy', 'continued'): {'to': 1}\n",
            "96. Context ('continued', 'to'): {'grow': 1}\n",
            "97. Context ('to', 'grow'): {'as': 1}\n",
            "98. Context ('grow', 'as'): {'his': 1}\n",
            "99. Context ('as', 'his'): {'adventures': 1}\n",
            "100. Context ('were', 'recounted'): {'by': 1}\n",
            "101. Context ('recounted', 'by'): {'bards': 1}\n",
            "102. Context ('by', 'bards'): {'and': 1}\n",
            "103. Context ('bards', 'and'): {'storytellers': 1}\n",
            "104. Context ('and', 'storytellers'): {'as': 1}\n",
            "105. Context ('storytellers', 'as'): {'time': 1}\n",
            "106. Context ('as', 'time'): {'passed': 1}\n",
            "107. Context ('time', 'passed'): {'legends': 1}\n",
            "108. Context ('passed', 'legends'): {'and': 1}\n",
            "109. Context ('legends', 'and'): {'myths': 1}\n",
            "110. Context ('and', 'myths'): {'were': 1}\n",
            "111. Context ('myths', 'were'): {'born': 1}\n",
            "112. Context ('were', 'born'): {'from': 1}\n",
            "113. Context ('born', 'from'): {'his': 1}\n",
            "114. Context ('from', 'his'): {'deeds': 1}\n",
            "115. Context ('his', 'deeds'): {'every': 1}\n",
            "116. Context ('deeds', 'every'): {'town': 1}\n",
            "117. Context ('every', 'town'): {'had': 1}\n",
            "118. Context ('town', 'had'): {'a': 1}\n",
            "119. Context ('had', 'a'): {'story': 1}\n",
            "120. Context ('a', 'story'): {'and': 1}\n",
            "121. Context ('story', 'and'): {'every': 1}\n",
            "122. Context ('and', 'every'): {'child': 1}\n",
            "123. Context ('every', 'child'): {'dreamed': 1}\n",
            "124. Context ('child', 'dreamed'): {'of': 1}\n",
            "125. Context ('dreamed', 'of'): {'a': 1}\n",
            "126. Context ('of', 'a'): {'hero': 1}\n",
            "127. Context ('a', 'hero'): {'like': 1}\n",
            "128. Context ('hero', 'like'): {'him': 1}\n",
            "\n",
            "4. Full Probability Distributions for Multiple Sample Contexts:\n",
            "\n",
            "Context: ('the', 'knight')\n",
            "  1. Word: 'journeyed' - Probability: 0.333\n",
            "  2. Word: 'was' - Probability: 0.333\n",
            "  3. Word: 'would' - Probability: 0.333\n",
            "  4. Word: 'a' - Probability: 0.000\n",
            "  5. Word: 'adventures' - Probability: 0.000\n",
            "  6. Word: 'all' - Probability: 0.000\n",
            "  7. Word: 'an' - Probability: 0.000\n",
            "  8. Word: 'and' - Probability: 0.000\n",
            "  9. Word: 'as' - Probability: 0.000\n",
            "  10. Word: 'away' - Probability: 0.000\n",
            "  11. Word: 'bards' - Probability: 0.000\n",
            "  12. Word: 'believed' - Probability: 0.000\n",
            "  13. Word: 'born' - Probability: 0.000\n",
            "  14. Word: 'brave' - Probability: 0.000\n",
            "  15. Word: 'by' - Probability: 0.000\n",
            "  16. Word: 'child' - Probability: 0.000\n",
            "  17. Word: 'continued' - Probability: 0.000\n",
            "  18. Word: 'courage' - Probability: 0.000\n",
            "  19. Word: 'day' - Probability: 0.000\n",
            "  20. Word: 'deeds' - Probability: 0.000\n",
            "  21. Word: 'doom' - Probability: 0.000\n",
            "  22. Word: 'dragons' - Probability: 0.000\n",
            "  23. Word: 'dreamed' - Probability: 0.000\n",
            "  24. Word: 'every' - Probability: 0.000\n",
            "  25. Word: 'exploits' - Probability: 0.000\n",
            "  26. Word: 'far' - Probability: 0.000\n",
            "  27. Word: 'fierce' - Probability: 0.000\n",
            "  28. Word: 'for' - Probability: 0.000\n",
            "  29. Word: 'forests' - Probability: 0.000\n",
            "  30. Word: 'fought' - Probability: 0.000\n",
            "  31. Word: 'from' - Probability: 0.000\n",
            "  32. Word: 'grow' - Probability: 0.000\n",
            "  33. Word: 'had' - Probability: 0.000\n",
            "  34. Word: 'heard' - Probability: 0.000\n",
            "  35. Word: 'helped' - Probability: 0.000\n",
            "  36. Word: 'hero' - Probability: 0.000\n",
            "  37. Word: 'heroism' - Probability: 0.000\n",
            "  38. Word: 'him' - Probability: 0.000\n",
            "  39. Word: 'his' - Probability: 0.000\n",
            "  40. Word: 'hope' - Probability: 0.000\n",
            "  41. Word: 'impending' - Probability: 0.000\n",
            "  42. Word: 'in' - Probability: 0.000\n",
            "  43. Word: 'inspiration' - Probability: 0.000\n",
            "  44. Word: 'it' - Probability: 0.000\n",
            "  45. Word: 'kingdom' - Probability: 0.000\n",
            "  46. Word: 'knight' - Probability: 0.000\n",
            "  47. Word: 'knights' - Probability: 0.000\n",
            "  48. Word: 'known' - Probability: 0.000\n",
            "  49. Word: 'land' - Probability: 0.000\n",
            "  50. Word: 'legacy' - Probability: 0.000\n",
            "  51. Word: 'legends' - Probability: 0.000\n",
            "  52. Word: 'like' - Probability: 0.000\n",
            "  53. Word: 'lived' - Probability: 0.000\n",
            "  54. Word: 'many' - Probability: 0.000\n",
            "  55. Word: 'meanwhile' - Probability: 0.000\n",
            "  56. Word: 'mysterious' - Probability: 0.000\n",
            "  57. Word: 'myths' - Probability: 0.000\n",
            "  58. Word: 'need' - Probability: 0.000\n",
            "  59. Word: 'of' - Probability: 0.000\n",
            "  60. Word: 'often' - Probability: 0.000\n",
            "  61. Word: 'once' - Probability: 0.000\n",
            "  62. Word: 'one' - Probability: 0.000\n",
            "  63. Word: 'passed' - Probability: 0.000\n",
            "  64. Word: 'people' - Probability: 0.000\n",
            "  65. Word: 'recounted' - Probability: 0.000\n",
            "  66. Word: 'return' - Probability: 0.000\n",
            "  67. Word: 'save' - Probability: 0.000\n",
            "  68. Word: 'small' - Probability: 0.000\n",
            "  69. Word: 'speak' - Probability: 0.000\n",
            "  70. Word: 'stories' - Probability: 0.000\n",
            "  71. Word: 'story' - Probability: 0.000\n",
            "  72. Word: 'storytellers' - Probability: 0.000\n",
            "  73. Word: 'tales' - Probability: 0.000\n",
            "  74. Word: 'that' - Probability: 0.000\n",
            "  75. Word: 'the' - Probability: 0.000\n",
            "  76. Word: 'them' - Probability: 0.000\n",
            "  77. Word: 'there' - Probability: 0.000\n",
            "  78. Word: 'those' - Probability: 0.000\n",
            "  79. Word: 'thrived' - Probability: 0.000\n",
            "  80. Word: 'through' - Probability: 0.000\n",
            "  81. Word: 'throughout' - Probability: 0.000\n",
            "  82. Word: 'time' - Probability: 0.000\n",
            "  83. Word: 'to' - Probability: 0.000\n",
            "  84. Word: 'told' - Probability: 0.000\n",
            "  85. Word: 'town' - Probability: 0.000\n",
            "  86. Word: 'upon' - Probability: 0.000\n",
            "  87. Word: 'valor' - Probability: 0.000\n",
            "  88. Word: 'village' - Probability: 0.000\n",
            "  89. Word: 'villagers' - Probability: 0.000\n",
            "  90. Word: 'were' - Probability: 0.000\n",
            "  91. Word: 'who' - Probability: 0.000\n",
            "  92. Word: 'with' - Probability: 0.000\n",
            "\n",
            "Context: ('once', 'upon')\n",
            "  1. Word: 'a' - Probability: 1.000\n",
            "  2. Word: 'adventures' - Probability: 0.000\n",
            "  3. Word: 'all' - Probability: 0.000\n",
            "  4. Word: 'an' - Probability: 0.000\n",
            "  5. Word: 'and' - Probability: 0.000\n",
            "  6. Word: 'as' - Probability: 0.000\n",
            "  7. Word: 'away' - Probability: 0.000\n",
            "  8. Word: 'bards' - Probability: 0.000\n",
            "  9. Word: 'believed' - Probability: 0.000\n",
            "  10. Word: 'born' - Probability: 0.000\n",
            "  11. Word: 'brave' - Probability: 0.000\n",
            "  12. Word: 'by' - Probability: 0.000\n",
            "  13. Word: 'child' - Probability: 0.000\n",
            "  14. Word: 'continued' - Probability: 0.000\n",
            "  15. Word: 'courage' - Probability: 0.000\n",
            "  16. Word: 'day' - Probability: 0.000\n",
            "  17. Word: 'deeds' - Probability: 0.000\n",
            "  18. Word: 'doom' - Probability: 0.000\n",
            "  19. Word: 'dragons' - Probability: 0.000\n",
            "  20. Word: 'dreamed' - Probability: 0.000\n",
            "  21. Word: 'every' - Probability: 0.000\n",
            "  22. Word: 'exploits' - Probability: 0.000\n",
            "  23. Word: 'far' - Probability: 0.000\n",
            "  24. Word: 'fierce' - Probability: 0.000\n",
            "  25. Word: 'for' - Probability: 0.000\n",
            "  26. Word: 'forests' - Probability: 0.000\n",
            "  27. Word: 'fought' - Probability: 0.000\n",
            "  28. Word: 'from' - Probability: 0.000\n",
            "  29. Word: 'grow' - Probability: 0.000\n",
            "  30. Word: 'had' - Probability: 0.000\n",
            "  31. Word: 'heard' - Probability: 0.000\n",
            "  32. Word: 'helped' - Probability: 0.000\n",
            "  33. Word: 'hero' - Probability: 0.000\n",
            "  34. Word: 'heroism' - Probability: 0.000\n",
            "  35. Word: 'him' - Probability: 0.000\n",
            "  36. Word: 'his' - Probability: 0.000\n",
            "  37. Word: 'hope' - Probability: 0.000\n",
            "  38. Word: 'impending' - Probability: 0.000\n",
            "  39. Word: 'in' - Probability: 0.000\n",
            "  40. Word: 'inspiration' - Probability: 0.000\n",
            "  41. Word: 'it' - Probability: 0.000\n",
            "  42. Word: 'journeyed' - Probability: 0.000\n",
            "  43. Word: 'kingdom' - Probability: 0.000\n",
            "  44. Word: 'knight' - Probability: 0.000\n",
            "  45. Word: 'knights' - Probability: 0.000\n",
            "  46. Word: 'known' - Probability: 0.000\n",
            "  47. Word: 'land' - Probability: 0.000\n",
            "  48. Word: 'legacy' - Probability: 0.000\n",
            "  49. Word: 'legends' - Probability: 0.000\n",
            "  50. Word: 'like' - Probability: 0.000\n",
            "  51. Word: 'lived' - Probability: 0.000\n",
            "  52. Word: 'many' - Probability: 0.000\n",
            "  53. Word: 'meanwhile' - Probability: 0.000\n",
            "  54. Word: 'mysterious' - Probability: 0.000\n",
            "  55. Word: 'myths' - Probability: 0.000\n",
            "  56. Word: 'need' - Probability: 0.000\n",
            "  57. Word: 'of' - Probability: 0.000\n",
            "  58. Word: 'often' - Probability: 0.000\n",
            "  59. Word: 'once' - Probability: 0.000\n",
            "  60. Word: 'one' - Probability: 0.000\n",
            "  61. Word: 'passed' - Probability: 0.000\n",
            "  62. Word: 'people' - Probability: 0.000\n",
            "  63. Word: 'recounted' - Probability: 0.000\n",
            "  64. Word: 'return' - Probability: 0.000\n",
            "  65. Word: 'save' - Probability: 0.000\n",
            "  66. Word: 'small' - Probability: 0.000\n",
            "  67. Word: 'speak' - Probability: 0.000\n",
            "  68. Word: 'stories' - Probability: 0.000\n",
            "  69. Word: 'story' - Probability: 0.000\n",
            "  70. Word: 'storytellers' - Probability: 0.000\n",
            "  71. Word: 'tales' - Probability: 0.000\n",
            "  72. Word: 'that' - Probability: 0.000\n",
            "  73. Word: 'the' - Probability: 0.000\n",
            "  74. Word: 'them' - Probability: 0.000\n",
            "  75. Word: 'there' - Probability: 0.000\n",
            "  76. Word: 'those' - Probability: 0.000\n",
            "  77. Word: 'thrived' - Probability: 0.000\n",
            "  78. Word: 'through' - Probability: 0.000\n",
            "  79. Word: 'throughout' - Probability: 0.000\n",
            "  80. Word: 'time' - Probability: 0.000\n",
            "  81. Word: 'to' - Probability: 0.000\n",
            "  82. Word: 'told' - Probability: 0.000\n",
            "  83. Word: 'town' - Probability: 0.000\n",
            "  84. Word: 'upon' - Probability: 0.000\n",
            "  85. Word: 'valor' - Probability: 0.000\n",
            "  86. Word: 'village' - Probability: 0.000\n",
            "  87. Word: 'villagers' - Probability: 0.000\n",
            "  88. Word: 'was' - Probability: 0.000\n",
            "  89. Word: 'were' - Probability: 0.000\n",
            "  90. Word: 'who' - Probability: 0.000\n",
            "  91. Word: 'with' - Probability: 0.000\n",
            "  92. Word: 'would' - Probability: 0.000\n",
            "\n",
            "Context: ('in', 'a')\n",
            "  1. Word: 'land' - Probability: 0.500\n",
            "  2. Word: 'small' - Probability: 0.500\n",
            "  3. Word: 'a' - Probability: 0.000\n",
            "  4. Word: 'adventures' - Probability: 0.000\n",
            "  5. Word: 'all' - Probability: 0.000\n",
            "  6. Word: 'an' - Probability: 0.000\n",
            "  7. Word: 'and' - Probability: 0.000\n",
            "  8. Word: 'as' - Probability: 0.000\n",
            "  9. Word: 'away' - Probability: 0.000\n",
            "  10. Word: 'bards' - Probability: 0.000\n",
            "  11. Word: 'believed' - Probability: 0.000\n",
            "  12. Word: 'born' - Probability: 0.000\n",
            "  13. Word: 'brave' - Probability: 0.000\n",
            "  14. Word: 'by' - Probability: 0.000\n",
            "  15. Word: 'child' - Probability: 0.000\n",
            "  16. Word: 'continued' - Probability: 0.000\n",
            "  17. Word: 'courage' - Probability: 0.000\n",
            "  18. Word: 'day' - Probability: 0.000\n",
            "  19. Word: 'deeds' - Probability: 0.000\n",
            "  20. Word: 'doom' - Probability: 0.000\n",
            "  21. Word: 'dragons' - Probability: 0.000\n",
            "  22. Word: 'dreamed' - Probability: 0.000\n",
            "  23. Word: 'every' - Probability: 0.000\n",
            "  24. Word: 'exploits' - Probability: 0.000\n",
            "  25. Word: 'far' - Probability: 0.000\n",
            "  26. Word: 'fierce' - Probability: 0.000\n",
            "  27. Word: 'for' - Probability: 0.000\n",
            "  28. Word: 'forests' - Probability: 0.000\n",
            "  29. Word: 'fought' - Probability: 0.000\n",
            "  30. Word: 'from' - Probability: 0.000\n",
            "  31. Word: 'grow' - Probability: 0.000\n",
            "  32. Word: 'had' - Probability: 0.000\n",
            "  33. Word: 'heard' - Probability: 0.000\n",
            "  34. Word: 'helped' - Probability: 0.000\n",
            "  35. Word: 'hero' - Probability: 0.000\n",
            "  36. Word: 'heroism' - Probability: 0.000\n",
            "  37. Word: 'him' - Probability: 0.000\n",
            "  38. Word: 'his' - Probability: 0.000\n",
            "  39. Word: 'hope' - Probability: 0.000\n",
            "  40. Word: 'impending' - Probability: 0.000\n",
            "  41. Word: 'in' - Probability: 0.000\n",
            "  42. Word: 'inspiration' - Probability: 0.000\n",
            "  43. Word: 'it' - Probability: 0.000\n",
            "  44. Word: 'journeyed' - Probability: 0.000\n",
            "  45. Word: 'kingdom' - Probability: 0.000\n",
            "  46. Word: 'knight' - Probability: 0.000\n",
            "  47. Word: 'knights' - Probability: 0.000\n",
            "  48. Word: 'known' - Probability: 0.000\n",
            "  49. Word: 'legacy' - Probability: 0.000\n",
            "  50. Word: 'legends' - Probability: 0.000\n",
            "  51. Word: 'like' - Probability: 0.000\n",
            "  52. Word: 'lived' - Probability: 0.000\n",
            "  53. Word: 'many' - Probability: 0.000\n",
            "  54. Word: 'meanwhile' - Probability: 0.000\n",
            "  55. Word: 'mysterious' - Probability: 0.000\n",
            "  56. Word: 'myths' - Probability: 0.000\n",
            "  57. Word: 'need' - Probability: 0.000\n",
            "  58. Word: 'of' - Probability: 0.000\n",
            "  59. Word: 'often' - Probability: 0.000\n",
            "  60. Word: 'once' - Probability: 0.000\n",
            "  61. Word: 'one' - Probability: 0.000\n",
            "  62. Word: 'passed' - Probability: 0.000\n",
            "  63. Word: 'people' - Probability: 0.000\n",
            "  64. Word: 'recounted' - Probability: 0.000\n",
            "  65. Word: 'return' - Probability: 0.000\n",
            "  66. Word: 'save' - Probability: 0.000\n",
            "  67. Word: 'speak' - Probability: 0.000\n",
            "  68. Word: 'stories' - Probability: 0.000\n",
            "  69. Word: 'story' - Probability: 0.000\n",
            "  70. Word: 'storytellers' - Probability: 0.000\n",
            "  71. Word: 'tales' - Probability: 0.000\n",
            "  72. Word: 'that' - Probability: 0.000\n",
            "  73. Word: 'the' - Probability: 0.000\n",
            "  74. Word: 'them' - Probability: 0.000\n",
            "  75. Word: 'there' - Probability: 0.000\n",
            "  76. Word: 'those' - Probability: 0.000\n",
            "  77. Word: 'thrived' - Probability: 0.000\n",
            "  78. Word: 'through' - Probability: 0.000\n",
            "  79. Word: 'throughout' - Probability: 0.000\n",
            "  80. Word: 'time' - Probability: 0.000\n",
            "  81. Word: 'to' - Probability: 0.000\n",
            "  82. Word: 'told' - Probability: 0.000\n",
            "  83. Word: 'town' - Probability: 0.000\n",
            "  84. Word: 'upon' - Probability: 0.000\n",
            "  85. Word: 'valor' - Probability: 0.000\n",
            "  86. Word: 'village' - Probability: 0.000\n",
            "  87. Word: 'villagers' - Probability: 0.000\n",
            "  88. Word: 'was' - Probability: 0.000\n",
            "  89. Word: 'were' - Probability: 0.000\n",
            "  90. Word: 'who' - Probability: 0.000\n",
            "  91. Word: 'with' - Probability: 0.000\n",
            "  92. Word: 'would' - Probability: 0.000\n",
            "\n",
            "Context: ('his', 'story')\n",
            "  1. Word: 'was' - Probability: 1.000\n",
            "  2. Word: 'a' - Probability: 0.000\n",
            "  3. Word: 'adventures' - Probability: 0.000\n",
            "  4. Word: 'all' - Probability: 0.000\n",
            "  5. Word: 'an' - Probability: 0.000\n",
            "  6. Word: 'and' - Probability: 0.000\n",
            "  7. Word: 'as' - Probability: 0.000\n",
            "  8. Word: 'away' - Probability: 0.000\n",
            "  9. Word: 'bards' - Probability: 0.000\n",
            "  10. Word: 'believed' - Probability: 0.000\n",
            "  11. Word: 'born' - Probability: 0.000\n",
            "  12. Word: 'brave' - Probability: 0.000\n",
            "  13. Word: 'by' - Probability: 0.000\n",
            "  14. Word: 'child' - Probability: 0.000\n",
            "  15. Word: 'continued' - Probability: 0.000\n",
            "  16. Word: 'courage' - Probability: 0.000\n",
            "  17. Word: 'day' - Probability: 0.000\n",
            "  18. Word: 'deeds' - Probability: 0.000\n",
            "  19. Word: 'doom' - Probability: 0.000\n",
            "  20. Word: 'dragons' - Probability: 0.000\n",
            "  21. Word: 'dreamed' - Probability: 0.000\n",
            "  22. Word: 'every' - Probability: 0.000\n",
            "  23. Word: 'exploits' - Probability: 0.000\n",
            "  24. Word: 'far' - Probability: 0.000\n",
            "  25. Word: 'fierce' - Probability: 0.000\n",
            "  26. Word: 'for' - Probability: 0.000\n",
            "  27. Word: 'forests' - Probability: 0.000\n",
            "  28. Word: 'fought' - Probability: 0.000\n",
            "  29. Word: 'from' - Probability: 0.000\n",
            "  30. Word: 'grow' - Probability: 0.000\n",
            "  31. Word: 'had' - Probability: 0.000\n",
            "  32. Word: 'heard' - Probability: 0.000\n",
            "  33. Word: 'helped' - Probability: 0.000\n",
            "  34. Word: 'hero' - Probability: 0.000\n",
            "  35. Word: 'heroism' - Probability: 0.000\n",
            "  36. Word: 'him' - Probability: 0.000\n",
            "  37. Word: 'his' - Probability: 0.000\n",
            "  38. Word: 'hope' - Probability: 0.000\n",
            "  39. Word: 'impending' - Probability: 0.000\n",
            "  40. Word: 'in' - Probability: 0.000\n",
            "  41. Word: 'inspiration' - Probability: 0.000\n",
            "  42. Word: 'it' - Probability: 0.000\n",
            "  43. Word: 'journeyed' - Probability: 0.000\n",
            "  44. Word: 'kingdom' - Probability: 0.000\n",
            "  45. Word: 'knight' - Probability: 0.000\n",
            "  46. Word: 'knights' - Probability: 0.000\n",
            "  47. Word: 'known' - Probability: 0.000\n",
            "  48. Word: 'land' - Probability: 0.000\n",
            "  49. Word: 'legacy' - Probability: 0.000\n",
            "  50. Word: 'legends' - Probability: 0.000\n",
            "  51. Word: 'like' - Probability: 0.000\n",
            "  52. Word: 'lived' - Probability: 0.000\n",
            "  53. Word: 'many' - Probability: 0.000\n",
            "  54. Word: 'meanwhile' - Probability: 0.000\n",
            "  55. Word: 'mysterious' - Probability: 0.000\n",
            "  56. Word: 'myths' - Probability: 0.000\n",
            "  57. Word: 'need' - Probability: 0.000\n",
            "  58. Word: 'of' - Probability: 0.000\n",
            "  59. Word: 'often' - Probability: 0.000\n",
            "  60. Word: 'once' - Probability: 0.000\n",
            "  61. Word: 'one' - Probability: 0.000\n",
            "  62. Word: 'passed' - Probability: 0.000\n",
            "  63. Word: 'people' - Probability: 0.000\n",
            "  64. Word: 'recounted' - Probability: 0.000\n",
            "  65. Word: 'return' - Probability: 0.000\n",
            "  66. Word: 'save' - Probability: 0.000\n",
            "  67. Word: 'small' - Probability: 0.000\n",
            "  68. Word: 'speak' - Probability: 0.000\n",
            "  69. Word: 'stories' - Probability: 0.000\n",
            "  70. Word: 'story' - Probability: 0.000\n",
            "  71. Word: 'storytellers' - Probability: 0.000\n",
            "  72. Word: 'tales' - Probability: 0.000\n",
            "  73. Word: 'that' - Probability: 0.000\n",
            "  74. Word: 'the' - Probability: 0.000\n",
            "  75. Word: 'them' - Probability: 0.000\n",
            "  76. Word: 'there' - Probability: 0.000\n",
            "  77. Word: 'those' - Probability: 0.000\n",
            "  78. Word: 'thrived' - Probability: 0.000\n",
            "  79. Word: 'through' - Probability: 0.000\n",
            "  80. Word: 'throughout' - Probability: 0.000\n",
            "  81. Word: 'time' - Probability: 0.000\n",
            "  82. Word: 'to' - Probability: 0.000\n",
            "  83. Word: 'told' - Probability: 0.000\n",
            "  84. Word: 'town' - Probability: 0.000\n",
            "  85. Word: 'upon' - Probability: 0.000\n",
            "  86. Word: 'valor' - Probability: 0.000\n",
            "  87. Word: 'village' - Probability: 0.000\n",
            "  88. Word: 'villagers' - Probability: 0.000\n",
            "  89. Word: 'were' - Probability: 0.000\n",
            "  90. Word: 'who' - Probability: 0.000\n",
            "  91. Word: 'with' - Probability: 0.000\n",
            "  92. Word: 'would' - Probability: 0.000\n",
            "\n",
            "Context: ('every', 'town')\n",
            "  1. Word: 'had' - Probability: 1.000\n",
            "  2. Word: 'a' - Probability: 0.000\n",
            "  3. Word: 'adventures' - Probability: 0.000\n",
            "  4. Word: 'all' - Probability: 0.000\n",
            "  5. Word: 'an' - Probability: 0.000\n",
            "  6. Word: 'and' - Probability: 0.000\n",
            "  7. Word: 'as' - Probability: 0.000\n",
            "  8. Word: 'away' - Probability: 0.000\n",
            "  9. Word: 'bards' - Probability: 0.000\n",
            "  10. Word: 'believed' - Probability: 0.000\n",
            "  11. Word: 'born' - Probability: 0.000\n",
            "  12. Word: 'brave' - Probability: 0.000\n",
            "  13. Word: 'by' - Probability: 0.000\n",
            "  14. Word: 'child' - Probability: 0.000\n",
            "  15. Word: 'continued' - Probability: 0.000\n",
            "  16. Word: 'courage' - Probability: 0.000\n",
            "  17. Word: 'day' - Probability: 0.000\n",
            "  18. Word: 'deeds' - Probability: 0.000\n",
            "  19. Word: 'doom' - Probability: 0.000\n",
            "  20. Word: 'dragons' - Probability: 0.000\n",
            "  21. Word: 'dreamed' - Probability: 0.000\n",
            "  22. Word: 'every' - Probability: 0.000\n",
            "  23. Word: 'exploits' - Probability: 0.000\n",
            "  24. Word: 'far' - Probability: 0.000\n",
            "  25. Word: 'fierce' - Probability: 0.000\n",
            "  26. Word: 'for' - Probability: 0.000\n",
            "  27. Word: 'forests' - Probability: 0.000\n",
            "  28. Word: 'fought' - Probability: 0.000\n",
            "  29. Word: 'from' - Probability: 0.000\n",
            "  30. Word: 'grow' - Probability: 0.000\n",
            "  31. Word: 'heard' - Probability: 0.000\n",
            "  32. Word: 'helped' - Probability: 0.000\n",
            "  33. Word: 'hero' - Probability: 0.000\n",
            "  34. Word: 'heroism' - Probability: 0.000\n",
            "  35. Word: 'him' - Probability: 0.000\n",
            "  36. Word: 'his' - Probability: 0.000\n",
            "  37. Word: 'hope' - Probability: 0.000\n",
            "  38. Word: 'impending' - Probability: 0.000\n",
            "  39. Word: 'in' - Probability: 0.000\n",
            "  40. Word: 'inspiration' - Probability: 0.000\n",
            "  41. Word: 'it' - Probability: 0.000\n",
            "  42. Word: 'journeyed' - Probability: 0.000\n",
            "  43. Word: 'kingdom' - Probability: 0.000\n",
            "  44. Word: 'knight' - Probability: 0.000\n",
            "  45. Word: 'knights' - Probability: 0.000\n",
            "  46. Word: 'known' - Probability: 0.000\n",
            "  47. Word: 'land' - Probability: 0.000\n",
            "  48. Word: 'legacy' - Probability: 0.000\n",
            "  49. Word: 'legends' - Probability: 0.000\n",
            "  50. Word: 'like' - Probability: 0.000\n",
            "  51. Word: 'lived' - Probability: 0.000\n",
            "  52. Word: 'many' - Probability: 0.000\n",
            "  53. Word: 'meanwhile' - Probability: 0.000\n",
            "  54. Word: 'mysterious' - Probability: 0.000\n",
            "  55. Word: 'myths' - Probability: 0.000\n",
            "  56. Word: 'need' - Probability: 0.000\n",
            "  57. Word: 'of' - Probability: 0.000\n",
            "  58. Word: 'often' - Probability: 0.000\n",
            "  59. Word: 'once' - Probability: 0.000\n",
            "  60. Word: 'one' - Probability: 0.000\n",
            "  61. Word: 'passed' - Probability: 0.000\n",
            "  62. Word: 'people' - Probability: 0.000\n",
            "  63. Word: 'recounted' - Probability: 0.000\n",
            "  64. Word: 'return' - Probability: 0.000\n",
            "  65. Word: 'save' - Probability: 0.000\n",
            "  66. Word: 'small' - Probability: 0.000\n",
            "  67. Word: 'speak' - Probability: 0.000\n",
            "  68. Word: 'stories' - Probability: 0.000\n",
            "  69. Word: 'story' - Probability: 0.000\n",
            "  70. Word: 'storytellers' - Probability: 0.000\n",
            "  71. Word: 'tales' - Probability: 0.000\n",
            "  72. Word: 'that' - Probability: 0.000\n",
            "  73. Word: 'the' - Probability: 0.000\n",
            "  74. Word: 'them' - Probability: 0.000\n",
            "  75. Word: 'there' - Probability: 0.000\n",
            "  76. Word: 'those' - Probability: 0.000\n",
            "  77. Word: 'thrived' - Probability: 0.000\n",
            "  78. Word: 'through' - Probability: 0.000\n",
            "  79. Word: 'throughout' - Probability: 0.000\n",
            "  80. Word: 'time' - Probability: 0.000\n",
            "  81. Word: 'to' - Probability: 0.000\n",
            "  82. Word: 'told' - Probability: 0.000\n",
            "  83. Word: 'town' - Probability: 0.000\n",
            "  84. Word: 'upon' - Probability: 0.000\n",
            "  85. Word: 'valor' - Probability: 0.000\n",
            "  86. Word: 'village' - Probability: 0.000\n",
            "  87. Word: 'villagers' - Probability: 0.000\n",
            "  88. Word: 'was' - Probability: 0.000\n",
            "  89. Word: 'were' - Probability: 0.000\n",
            "  90. Word: 'who' - Probability: 0.000\n",
            "  91. Word: 'with' - Probability: 0.000\n",
            "  92. Word: 'would' - Probability: 0.000\n",
            "\n",
            "5. Sentence Completion Examples:\n",
            "Example 1. Starting phrase: 'once upon'\n",
            "           Completed sentence: once upon a time in a land far away there lived a brave knight the knight was known for his valor and courage and many stories of his adventures were told throughout the kingdom the knight was known for his valor and courage and many stories of his adventures were\n",
            "\n",
            "Example 2. Starting phrase: 'the knight'\n",
            "           Completed sentence: the knight was known for his valor and courage and many stories of his adventures were told throughout the kingdom the knight was known for his valor and courage and many stories of his adventures were told throughout the kingdom the knight was known for his valor and courage and\n",
            "\n",
            "Example 3. Starting phrase: 'in a land'\n",
            "           Completed sentence: in a land far away there lived a brave knight the knight was known for his valor and courage and many stories of his adventures were told throughout the kingdom the knight was known for his valor and courage and many stories of his adventures were told throughout the kingdom\n",
            "\n",
            "Example 4. Starting phrase: 'his story'\n",
            "           Completed sentence: his story was an inspiration to all who heard it in a land far away there lived a brave knight the knight was known for his valor and courage and many stories of his adventures were told throughout the kingdom the knight was known for his valor and courage and\n",
            "\n",
            "Example 5. Starting phrase: 'every town'\n",
            "           Completed sentence: every town had a story and every child dreamed of a hero like him\n",
            "\n",
            "Explanation Summary:\n",
            "---------------------------------------------------------\n",
            "1. We defined a larger corpus containing multiple sentences to enrich the model's context.\n",
            "2. The corpus is preprocessed: it is converted to lowercase, punctuation is removed, and it is tokenized into words.\n",
            "3. A trigram model is built by mapping each 2-word context to the counts of possible following words.\n",
            "4. The vocabulary is extracted as the set of all unique tokens, sorted alphabetically.\n",
            "5. For any given context, we can compute the full probability distribution over the entire vocabulary.\n",
            "6. We demonstrated this with multiple sample contexts, showing the probability of each word being the next word.\n",
            "7. Finally, the sentence completion function uses the trigram model to extend multiple starting phrases.\n",
            "---------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "#################################################################\n",
        "# Step 1: Define a Larger Corpus and Preprocessing Function\n",
        "#################################################################\n",
        "\n",
        "# Here we define a larger corpus with multiple sentences and paragraphs.\n",
        "# This corpus contains a short narrative with various contexts and styles.\n",
        "corpus = \"\"\"\n",
        "Once upon a time in a land far away, there lived a brave knight.\n",
        "The knight was known for his valor and courage, and many stories of his adventures were told throughout the kingdom.\n",
        "The knight journeyed through mysterious forests, fought fierce dragons, and helped those in need.\n",
        "His story was an inspiration to all who heard it.\n",
        "In a small village, the people would often speak of the knight's exploits.\n",
        "The villagers believed that one day, the knight would return to save them from impending doom.\n",
        "Meanwhile, the kingdom thrived with tales of heroism and hope.\n",
        "The knight's legacy continued to grow as his adventures were recounted by bards and storytellers.\n",
        "As time passed, legends and myths were born from his deeds.\n",
        "Every town had a story, and every child dreamed of a hero like him.\n",
        "\"\"\"\n",
        "\n",
        "def tokenize(text):\n",
        "    \"\"\"\n",
        "    Preprocess the text by:\n",
        "      1. Converting to lowercase.\n",
        "      2. Removing punctuation and non-letter characters.\n",
        "      3. Splitting the text into individual words (tokens).\n",
        "    \"\"\"\n",
        "    text = text.lower()                              # Convert text to lowercase\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)              # Remove punctuation and non-letter characters\n",
        "    tokens = text.split()                            # Split text into tokens based on whitespace\n",
        "    return tokens\n",
        "\n",
        "# Tokenize the corpus and display the tokens.\n",
        "tokens = tokenize(corpus)\n",
        "print(\"1. Tokens from the corpus:\")\n",
        "print(tokens)\n",
        "\n",
        "#################################################################\n",
        "# Step 2: Build N-Gram (Trigram) Counts from the Corpus\n",
        "#################################################################\n",
        "\n",
        "# We build a trigram model (n=3) where each context is two words predicting a third word.\n",
        "n = 3\n",
        "\n",
        "# Create a dictionary mapping each 2-word context to a Counter of possible next words.\n",
        "ngrams_counts = defaultdict(Counter)\n",
        "for i in range(len(tokens) - n + 1):\n",
        "    context = tuple(tokens[i:i+n-1])  # First two words as context\n",
        "    next_word = tokens[i+n-1]         # Third word as the predicted word\n",
        "    ngrams_counts[context][next_word] += 1\n",
        "\n",
        "# Build the vocabulary: the sorted list of unique tokens in the corpus.\n",
        "vocabulary = sorted(set(tokens))\n",
        "print(\"\\n2. Vocabulary (sorted alphabetically):\")\n",
        "for idx, word in enumerate(vocabulary, 1):\n",
        "    print(f\"{idx}. {word}\")\n",
        "\n",
        "print(\"\\n3. Trigram Counts (contexts with their next words and counts):\")\n",
        "for idx, (context, counter) in enumerate(ngrams_counts.items(), 1):\n",
        "    print(f\"{idx}. Context {context}: {dict(counter)}\")\n",
        "\n",
        "#################################################################\n",
        "# Step 3: Define Functions for Next Word Prediction and Probability Distribution\n",
        "#################################################################\n",
        "\n",
        "def predict_next_word(context, ngrams_counts):\n",
        "    \"\"\"\n",
        "    Predict the next word using maximum likelihood estimation.\n",
        "    Returns the most common next word for the given context.\n",
        "\n",
        "    Parameters:\n",
        "      - context: A tuple or list of words (expected length is n-1, i.e., 2 words for a trigram).\n",
        "      - ngrams_counts: Dictionary mapping contexts to counters of next words.\n",
        "\n",
        "    Returns:\n",
        "      - The predicted next word as a string, or None if the context is not found.\n",
        "    \"\"\"\n",
        "    context = tuple(context)\n",
        "    if context in ngrams_counts:\n",
        "        next_word = ngrams_counts[context].most_common(1)[0][0]\n",
        "        return next_word\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def get_full_next_word_probabilities(context, ngrams_counts, vocabulary):\n",
        "    \"\"\"\n",
        "    For a given context, return a dictionary mapping each word in the entire vocabulary\n",
        "    to its probability of being the next word.\n",
        "\n",
        "    If the context is found in the n-gram counts, probabilities are calculated as:\n",
        "      (Count of word following the context) / (Total counts for that context).\n",
        "    Words not observed after the context are assigned a probability of 0.\n",
        "\n",
        "    Parameters:\n",
        "      - context: A tuple or list of words (context for prediction).\n",
        "      - ngrams_counts: Dictionary mapping contexts to counters of next words.\n",
        "      - vocabulary: List of all unique tokens in the corpus.\n",
        "\n",
        "    Returns:\n",
        "      - A dictionary where keys are candidate words and values are their probabilities.\n",
        "    \"\"\"\n",
        "    context = tuple(context)\n",
        "    if context in ngrams_counts:\n",
        "        total_count = sum(ngrams_counts[context].values())\n",
        "        # Create a distribution that includes every word from the vocabulary.\n",
        "        dist = {word: ngrams_counts[context][word] / total_count if word in ngrams_counts[context] else 0.0\n",
        "                for word in vocabulary}\n",
        "    else:\n",
        "        # If the context is not found, assign a probability of 0.0 for every word.\n",
        "        dist = {word: 0.0 for word in vocabulary}\n",
        "    return dist\n",
        "\n",
        "#################################################################\n",
        "# Step 4: Show the Full Probability Distribution for Multiple Sample Contexts\n",
        "#################################################################\n",
        "\n",
        "# List of sample contexts to test.\n",
        "sample_contexts = [\n",
        "    ('the', 'knight'),\n",
        "    ('once', 'upon'),\n",
        "    ('in', 'a'),\n",
        "    ('his', 'story'),\n",
        "    ('every', 'town')\n",
        "]\n",
        "\n",
        "print(\"\\n4. Full Probability Distributions for Multiple Sample Contexts:\")\n",
        "for context in sample_contexts:\n",
        "    print(f\"\\nContext: {context}\")\n",
        "    prob_dist = get_full_next_word_probabilities(context, ngrams_counts, vocabulary)\n",
        "    # Sort the probability distribution in descending order of probability.\n",
        "    sorted_prob = sorted(prob_dist.items(), key=lambda x: -x[1])\n",
        "    for idx, (word, prob) in enumerate(sorted_prob, 1):\n",
        "        print(f\"  {idx}. Word: '{word}' - Probability: {prob:.3f}\")\n",
        "\n",
        "#################################################################\n",
        "# Step 5: Sentence Completion Examples for Multiple Starting Phrases\n",
        "#################################################################\n",
        "\n",
        "def complete_sentence(sentence, ngrams_counts, max_words=20):\n",
        "    \"\"\"\n",
        "    Complete a sentence by predicting and appending words until:\n",
        "      - The sentence reaches a specified maximum number of words, or\n",
        "      - No further prediction is available for the current context.\n",
        "\n",
        "    The function tokenizes the input sentence and then uses the last two words (the context)\n",
        "    to predict the next word. This process repeats until the sentence is complete.\n",
        "\n",
        "    Parameters:\n",
        "      - sentence: The starting sentence as a string.\n",
        "      - ngrams_counts: The dictionary containing trigram counts.\n",
        "      - max_words: The maximum total number of words for the completed sentence.\n",
        "\n",
        "    Returns:\n",
        "      - The completed sentence as a string.\n",
        "    \"\"\"\n",
        "    tokens = tokenize(sentence)\n",
        "    while len(tokens) < max_words:\n",
        "        # Use the last two words as the context (or all tokens if fewer than 2)\n",
        "        context = tokens[-(n-1):] if len(tokens) >= n-1 else tokens\n",
        "        next_word = predict_next_word(context, ngrams_counts)\n",
        "        if not next_word:\n",
        "            break\n",
        "        tokens.append(next_word)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# List of sample starting phrases.\n",
        "sample_sentences = [\n",
        "    \"once upon\",\n",
        "    \"the knight\",\n",
        "    \"in a land\",\n",
        "    \"his story\",\n",
        "    \"every town\"\n",
        "]\n",
        "\n",
        "print(\"\\n5. Sentence Completion Examples:\")\n",
        "for idx, sentence in enumerate(sample_sentences, 1):\n",
        "    completed = complete_sentence(sentence, ngrams_counts, max_words=50)\n",
        "    print(f\"Example {idx}. Starting phrase: '{sentence}'\")\n",
        "    print(f\"           Completed sentence: {completed}\\n\")\n",
        "\n",
        "#################################################################\n",
        "# Step 6: Explanation Summary\n",
        "#################################################################\n",
        "\n",
        "print(\"Explanation Summary:\")\n",
        "print(\"---------------------------------------------------------\")\n",
        "print(\"1. We defined a larger corpus containing multiple sentences to enrich the model's context.\")\n",
        "print(\"2. The corpus is preprocessed: it is converted to lowercase, punctuation is removed, and it is tokenized into words.\")\n",
        "print(\"3. A trigram model is built by mapping each 2-word context to the counts of possible following words.\")\n",
        "print(\"4. The vocabulary is extracted as the set of all unique tokens, sorted alphabetically.\")\n",
        "print(\"5. For any given context, we can compute the full probability distribution over the entire vocabulary.\")\n",
        "print(\"6. We demonstrated this with multiple sample contexts, showing the probability of each word being the next word.\")\n",
        "print(\"7. Finally, the sentence completion function uses the trigram model to extend multiple starting phrases.\")\n",
        "print(\"---------------------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SH_r06bFoCvG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}